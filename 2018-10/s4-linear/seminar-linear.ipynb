{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/logo_hse_black.jpg\"></center>\n",
    "\n",
    "<h1><center>Методы машинного обучения</center></h1>\n",
    "<h2><center>Семинар: линейные модели</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример: Стоимость автомобиля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите тренировочные данные и тестовые данные - уже знакомые нам данные по автомобилям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/accord_sedan_training.csv')\n",
    "df_test = pd.read_csv('./data/accord_sedan_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(x='mileage', y='price', kind='scatter', s=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что между стоимостью и пробегом зависимость линейная - давайте ее найдем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.mileage.values.reshape(-1, 1)\n",
    "y_train = df_train.price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Модель:\\nprice = %.2f + (%.2f)*mileage' % (model.intercept_, model.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте предсказание модели (прямую) вместе с данными на плоскости. Здесь можно либо явно взять уравнение прямой и посчитать значения в каждой точке, либо через predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(x='mileage', y='price', kind='scatter', s=120)\n",
    "\n",
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меры качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "**1. (R)MSE ((Root) Mean Squared Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{1}{N}\\sum\\limits_n^N (y_n - \\hat{y}_n)^2$$\n",
    "\n",
    "**2. MAE (Mean Absolute Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{1}{N}\\sum\\limits_n^N |y_n - \\hat{y}_n|$$\n",
    "\n",
    "* Чем плохи такие метрики?\n",
    "* Отличия - http://yahwes.github.io/2016/03/22/mae-rmse/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**3. RSE (Relative Squared Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\sqrt\\frac{\\sum\\limits_n^N (y_n - \\hat{y}_n)^2}{\\sum\\limits_n^N (y_n - \\bar{y})^2}$$\n",
    "\n",
    "**4. RAE (Relative Absolute Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{\\sum\\limits_n^N |y_n - \\hat{y}_n|}{\\sum\\limits_n^N |y_n - \\bar{y}|}$$\n",
    "\n",
    "**5. MAPE (Mean Absolute Persentage Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\frac{100}{N} \\sum\\limits_n^N\\left|\\frac{ y_n - \\hat{y}_n}{y_n}\\right|$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**6. RMSLE (Root Mean Squared Logarithmic Error)**\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\sqrt{\\frac{1}{N}\\sum\\limits_n^N(\\log(y_n + 1) - \\log(\\hat{y}_n + 1))^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y = 10000\n",
    "y_hat = np.linspace(0, 30000, 151)\n",
    "# log error\n",
    "error1 = np.sqrt((np.log(y+1) - np.log(y_hat + 1))**2)\n",
    "\n",
    "# squared error\n",
    "error2 = (y - y_hat)**2 /1000.\n",
    "\n",
    "plt.plot(y_hat, error1, label='RMSLE')\n",
    "plt.plot(y_hat, error2, label='MSE')\n",
    "plt.xlabel('$\\hat{y}$')\n",
    "plt.ylabel('Error')\n",
    "plt.title('true value y = %.1f' % y)\n",
    "plt.legend()\n",
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Средняя абсолютная ошибка %.2f' % mean_absolute_error(y_train, y_hat))\n",
    "print('Средняя квадратичная ошибка %.2f' % mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассмотреть более сложную меру: коэффициент детерминации $R^2$:\n",
    "\n",
    "* $TSS = \\sum_i (y^{(i)}-\\bar{y})^2$ - общая сумма квадратов (total sum of squares)\n",
    "* $RSS = \\sum_i (\\hat{y}^{(i)}-y^{(i)})^2$ - сумма квадратов остатков (residual sum of squares)\n",
    "* $ESS = \\sum_i (\\hat{y}^{(i)}-\\bar{y})^2$ - объясненная сумма квадратов (explained sum of squares)\n",
    "\n",
    "Для простоты будем считать, что\n",
    "$$TSS = ESS + RSS$$\n",
    "\n",
    "Тогда Коэффициент детерминации $R^2=1-\\frac{RSS}{TSS}$\n",
    "\n",
    "Рассчитайте его для нашей модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка значимости коэффициентов с помощью бутстрепа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интро в бутстреп\n",
    "\n",
    "Иногда для анализа данных полезно знать не только среднее значение какого-нибудь признака, но и его [доверительный интервал](http://www.machinelearning.ru/wiki/index.php?title=%D0%94%D0%BE%D0%B2%D0%B5%D1%80%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9_%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%B2%D0%B0%D0%BB). \n",
    "\n",
    "Из курса статистики известно, что если выборка $x$ подчиняются нормальному закону распределения и нам известно стандартное отклонение $\\sigma$ на *генеральной совокупности*, то доверительный интервал c доверительной вероятностью $(1-\\alpha)$ для среднего можно вычислить по следующей формуле:\n",
    "\n",
    "$$\\left( \\bar{x} - z_{1 - \\alpha/2}\\frac{\\sigma}{\\sqrt{n}}, \\bar{x} + z_{1 - \\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\right),$$\n",
    "\n",
    "где $\\bar{x}$ - выборочное среднее , $n$ - это размер выборки, а $z_{\\gamma}$ - это квантиль нормального распределения уровня $\\gamma$.\n",
    "\n",
    "Выберем какой-то признак и посчитаем доверительный интервал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train.price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем 95% доверительный интервал (alpha = 0.05)\n",
    "# Тогда просто согласно формуле\n",
    "\n",
    "sigma = x.std() # Вообще говоря, это неправда, но будем считать, что это знание свыше\n",
    "n = x.shape[0]\n",
    "z = 1.96 # 0.975 квантиль\n",
    "xm = x.mean()\n",
    "\n",
    "lb, rb = xm - z*sigma/np.sqrt(n), xm + z*sigma/np.sqrt(n)\n",
    "\n",
    "print('95%% доверительный интервал: (%.3f, %.3f)' % (lb, rb))\n",
    "print('Среднее %.3f' % xm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Есть другой, более универсальный способ для расчета доверительных интервалов любых статистик - метод [bootstap](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), идея которого заключается в многократной генерации выборок на базе имеющейся выборки.\n",
    "\n",
    "Для того, чтобы найти доверительный интервал методом bootstrap проделайте следующие шаги:\n",
    "1. Создайте случайную матрицу размера $150 \\times 1000$. $150$ - потому что в iris есть измерения по $150$ объектам, а $1000$ - это количество bootstrap-выборок, которое мы отсэмплируем. Значения в этой матрице должны быть целочисленными от 0 до 149 (включительно). Полученная матрица - матрица со случайными индексами элементов массива, для которого мы считаем доверительный интервал\n",
    "2. Выполните сэмплирование - должна получится новая матрица размера $150 \\times 1000$, но заполненная значениями из массива.\n",
    "3. Посчитайте среднее по каждому столбцу - получится массив выборочных средних.\n",
    "4. По массиву из пункта выше посчитайте 2.5% и 97.5% персентили - это и будут границы доверительного интервала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачем это нам? Для моделей мы можем точно также делать оценки каких-то их параметров.\n",
    "\n",
    "В частности, для линейной регрессии мы можем методом бутстрепа генерировать выборки для обучения, строить модели и запоминать полученные коэффициенты. \n",
    "\n",
    "Затем точно так же можно смотреть на доверительный интервал для коэффициентов\n",
    "\n",
    "Используйте бутстреп для данного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но есть различные статистические оценки для доверительных интервалов. Их можно либо считать [самому](https://math.stackexchange.com/questions/871601/confidence-interval-for-regression-coefficient-beta), либо использовать пакеты, в которых все расчитывается автоматом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.c_[X_train, np.ones_like(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = sm.OLS(y_train, exog=X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эффект регуляризации\n",
    "\n",
    "Теперь, давайте попробуем добавить столбец с \"километрами\" в наш датафрейм (линейная зависимость) и \n",
    "\n",
    "1. Посмотрим что будет с коэффициентами\n",
    "2. Добавим регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем  добавить остальные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Игрушечный пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку и опробуем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.r_[np.random.randn(20, 2) + [2, 2],\n",
    "          np.random.randn(20, 2) + [-2, -2]]\n",
    "y = [-1] * 20 + [1] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(X[:, 0],\n",
    "           X[:, 1],\n",
    "           c=y,\n",
    "           cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию на этих данных и нарисуем разделяющую гиперплоскость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0, \n",
    "                           fit_intercept=True, \n",
    "                           penalty='l2')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('w_0 = %f' % model.intercept_)\n",
    "print('w_1, w_2 = ', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нарисуем эту гиперплоскость\n",
    "w_0 = model.intercept_[0]\n",
    "w_1 = model.coef_[0][0]\n",
    "w_2 = model.coef_[0][1]\n",
    "\n",
    "x_1 = np.linspace(-4, 4, 10)\n",
    "x_2 = - (w_0 + w_1*x_1)/w_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(X[:, 0],\n",
    "           X[:, 1],\n",
    "           c=y,\n",
    "           cmap=plt.cm.Paired)\n",
    "plt.plot(x_1, x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример с текстами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем текстовые данные [отсюда](https://archive.ics.uci.edu/ml/machine-learning-databases/00331/). Архив содержит 3 файла с положительными и отрицательными отзывами с ресурсов\n",
    "* imdb.com\n",
    "* amazon.com\n",
    "* yelp.com\n",
    "\n",
    "Формат файла следующий:\n",
    "<отзыв>\\t<метка>\\n\n",
    "\n",
    "\n",
    "### Задача\n",
    "1. Загрузите тексты и метки классов в разные переменные\n",
    "2. Выберите меру качества классификации\n",
    "3. Обучите логистическую (без подбора гиперпараметров). Тексты представляются в виде мешка слов\n",
    "4. Выведите наиболее значимые слова из текста\n",
    "5. С помощью кросс-валидации найдите хорошие значения гиперпараметров для `CountVectorizer` и `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sentiment/imdb_labelled.txt', sep='\\t', header=None, names=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=4, max_df=0.95, stop_words='english', ngram_range=(1,1))),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "142px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
